---
title: "Comparative Experiments - Assumption Checking"
author: "Dr Austin R Brown"
institute: "Kennesaw State University"
format: beamer
editor: visual
execute:
  echo: true
  include: true
  warning: false
  message: false
  tidy: false
---

## Introduction

-   So far, we have discussed how to perform comparative experiments using a completely randomized design (CRD).

\vskip 0.10 in

-   The specific methods we have used are the independent means $t$-test and the one-way ANOVA method.

\vskip 0.10 in

-   When we first introduced these methods, we had said there are a few assumptions which need to be reasonably met in order for us to feel confident in the results we draw from the $F$ and Post-Hoc tests, respecitvely.

## Assumptions for One-Way ANOVA

-   Because an independent means $t$-test is a special case of the one-way ANOVA, the assumptions for the $t$-test are the same as the one-way ANOVA.

\vskip 0.10 in

-   Specifically, the assumptions for the one-way ANOVA are:

    1.  The populations from which the samples are drawn are normally distributed.
    2.  The populations from which the samples are drawn have equal variances.
    3.  The observations are independent of one another.

## Assumptions for One-Way ANOVA: Normality

-   The first assumption is that the populations from which the samples are drawn are normally distributed.

\vskip 0.10 in

-   Recall that:

$$ \varepsilon_{ij} \sim N(0, \sigma^2) $$

-   This means that the residuals are normally distributed with a mean of 0 and a constant variance term, $\sigma^2$.

## Assumptions for One-Way ANOVA: Normality

-   This tells us that we can check the normality assumption by examining the residuals.

\vskip 0.10 in

-   Generally when performing any assumption test, I recommend using a graphical method in addition to a formal test.

\vskip 0.10 in

-   The most common graphical method is the Q-Q plot.

## Assumptions for One-Way ANOVA: Normality

-   The Q-Q Plot is a graphical method for comparing the theoretical and empirical probability distributions of the residuals by plotting their quantiles against each other in a scatterplot format.

\vskip 0.10 in

-   If the residuals are normally distributed, the points on the Q-Q plot will fall along a straight, positively sloped line.

\vskip 0.10 in

-   If the residuals are not normally distributed, the points will deviate from the straight line.

## Assumptions for One-Way ANOVA: Normality

-   Let's use the Egg Rating example data to build a Q-Q plot.

```{r,eval=F}
library(tidyverse)
library(readxl)
## Read in the Data ##
egg_data <- read_excel("Egg Rating.xlsx")
## Build the Model ##
egg_mod <- aov(Rating ~ Technique, data = egg_data)
## Build a QQ Plot using geom_qq ##
egg_data |>
  ggplot(aes(sample=resid(egg_mod))) +
  geom_qq() +
  geom_qq_line() +
  labs(x = "Theoretical Values",
       y = "Empirical Values") +
  theme_classic()
```

## Assumptions for One-Way ANOVA: Normality

```{r,echo=F}
library(tidyverse)
library(readxl)
## Read in the Data ##
egg_data <- read_excel("Egg Rating.xlsx")
## Build the Model ##
egg_mod <- aov(Rating ~ Technique, data = egg_data)
## Build a QQ Plot using geom_qq ##
egg_data |>
  ggplot(aes(sample=resid(egg_mod))) +
  geom_qq() +
  geom_qq_line() +
  labs(x = "Theoretical Values",
       y = "Empirical Values") +
  theme_classic()
```

## Assumptions for One-Way ANOVA: Normality

-   As we can see, most of the points fall near the line bisecting the graph.

\vskip 0.10 in

-   While we do have some deviation, it doesn't seem to be substantial nor a large number of points.

\vskip 0.10 in

-   Thus, I would conclude that the Q-Q plot gives us evidence in support of the normality assumption.
    -   Note, this is subjective!

## Assumptions for One-Way ANOVA: Normality

```{r,echo=FALSE,include=TRUE,out.width="70%",out.height="80%",fig.align="center"}
knitr::include_graphics("PP Plot.jpg")
```

## Assumptions for One-Way ANOVA: Normality

-   Now, let's perform a formal test of normality of the residuals.

\vskip 0.10 in

-   There exist many, many tests of normality (e.g., Shapiro-Wilk, Kolmogorov-Smirnov, Anderson-Darling, etc.), but each of them has the same statistical hypotheses:

$$ H_0: \text{The Normality Assumption is Met} $$ $$ H_1: \text{The Normality Assumption is Not Met} $$

## Assumptions for One-Way ANOVA: Normality

-   One of my favorite tests is the Shaprio-Wilk Test, which we can perform using the `shapiro.test` function in R:

```{r}
## Perform Shapiro-Wilk Test ##
library(broom)
egg_mod |>
  resid() |>
  shapiro.test() |>
  tidy()
```

## Assumptions for One-Way ANOVA: Normality

-   Since $p > 0.05$, this indicates the data more strongly support the null hypothesis.

\vskip 0.10 in

-   Contextually this means that we have strong evidence in favor of the normality assumption being met.

\vskip 0.10 in

-   This, along with a relatively good looking Q-Q plot, means that we can feel confident that the normality assumption is reasonably met.

## Assumptions for One-Way ANOVA: Constant Variance

-   To test the constant variance assumption graphically, I like to plot the predicted values for $y_{ij}$, which are just the group means, $\bar{y}_{i.}$, versus the residuals.

\vskip 0.10 in

-   This gives us a sort of boxplot whose width we can use as a rough estimate of variability.

\vskip 0.10 in

-   This is reasonable considering the estimate of $\sigma^2$, denoted $\hat{\sigma}^2$, is calculated by:

$$ \hat{\sigma}^2 = \frac{1}{n - t}\sum_{i=1}^{t}\sum_{j=1}^{r_t}\varepsilon_{ij} = \frac{1}{n - t}\sum_{i=1}^{t}\sum_{j=1}^{r_t}(y_{ij} - \bar{y}_{i\cdot})^2 $$

## Assumptions for One-Way ANOVA: Constant Variance

```{r,eval=F}
## Build Scatterplot Evaluating Residuals vs 
## Predicted Values ##
egg_data |>
  ggplot(aes(x=fitted(egg_mod),y=resid(egg_mod))) +
  geom_point() +
  geom_hline(yintercept=0,linetype='dashed',
             color='red') +
  geom_hline(yintercept=3,color='blue') +
  geom_hline(yintercept=-3,color='blue') +
  labs(x = "Predicted y's",
       y = "Residuals") +
  theme_classic()
```

## Assumptions for One-Way ANOVA: Constant Variance

```{r,echo=F}
## Build Scatterplot Evaluating Residuals vs Predicted Values ##
egg_data |>
  ggplot(aes(x=fitted(egg_mod),y=resid(egg_mod))) +
  geom_point() +
  geom_hline(yintercept=0,linetype='dashed',
             color='red') +
  geom_hline(yintercept=3,color='blue') +
  geom_hline(yintercept=-3,color='blue') +
  labs(x = "Predicted y's",
       y = "Residuals") +
  theme_classic()
```

## Assumptions for One-Way ANOVA: Constant Variance

-   As we can see, for each group mean (shown by the vertical lines), the residuals are mostly centered around 0, which implies that the residual mean being approximately 0 seems reasonable.

\vskip 0.10 in

-   Additionally, while the residuals are not exactly the same width, they are not drastically different either.

\vskip 0.10 in

-   Thus, I would conclude that the constant variance assumption is reasonable.
    -   Again, the visual technique is somewhat subjective!!

## Assumptions for One-Way ANOVA: Constant Variance

-   The testing method we use for evaluating the constant variance assumption is called \textit{\underline{Levene's Test}}.

\vskip 0.10 in

-   Levene's Test evaluates the following statistical hypotheses:

$$H_0: \text{The Variances are Equal Across All Groups} $$ $$H_1: \text{At Least One Group has a Different Variance} $$

## Assumptions for One-Way ANOVA: Constant Variance

-   To perform this test in R, we can use the `leveneTest` function which is part of the `car` package:

```{r}
library(car)
leveneTest(egg_mod) |>
  tidy() |>
  select(statistic,p.value)
```

## Assumptions for One-Way ANOVA: Constant Variance

-   Since $p > 0.05$, this indicates the data more strongly support the null hypothesis.

\vskip 0.10 in

-   This, coupled with what we observed in the scatterplot, indicates that the constant variance assumption is also reasonably met.

## Assumptions for One-Way ANOVA: Independence of Observations

-   The final assumption we have for One-Way ANOVA is that all of our observations are independent of one another.

\vskip 0.10 in

-   While we do have a test for this (Durbin-Watson test), I tend to rely on the sampling technique as the measure of independence.

\vskip 0.10 in

-   In the egg example, if we select our panel participants in a reasonably random manner and further use randomization to partition the participants into each of the cooking technique treatments, it is reasonable to assume that may assessment of an egg has nothing to do with your assessment of an egg.

## Assumptions for One-Way ANOVA: Independence of Observations

-   If I were to ask people who were coming out of a mosque or synagogue to be part of an experiment where I was cooking eggs in bacon grease, this isn't random and thus I couldn't rely on the results.

\vskip 0.10 in

-   In most laboratory science types of experiments (like the Dog Toy or Can Cooler example), independence of observations is generally pretty reasonable.

\vskip 0.10 in

-   We have to be more mindful of our sampling technique when working with human participants to ensure that independence can be reasonably assumed.
